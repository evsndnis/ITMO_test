# Чат-бот для абитуриентов ИТМО

Изначальная задача заключалась в разработке чат-бота для абитуриентов, который помогал бы им выбрать магистерскую программу ИТМО и планировать обучение, используя информацию из учебных планов, скачанных с двух конкретных сайтов.

Процесс решения был разбит на несколько основных шагов:

## 1. Парсинг данных с сайтов и скачивание PDF-файлов с учебными планами

**Инструменты:**
Изначально использовались библиотеки `requests` для выполнения HTTP-запросов и `BeautifulSoup` для парсинга HTML-кода страниц.

**Проблемы и решения:**
* Первые попытки найти прямые ссылки на PDF-файлы по тегу `<a>` или по классу кнопки не увенчались успехом, так как кнопка "СКАЧАТЬ УЧЕБНЫЙ ПЛАН" не содержала прямого атрибута `href`, а другая PDF-ссылка вела на экзаменационные вопросы.
* Были предприняты попытки найти PDF-ссылки с помощью регулярных выражений (`re`) по характерным паттернам URL (`/upload/iblock/...pdf`), но это также не дало стабильного результата.
* **Ключевое решение:** Поскольку контент на сайте загружался динамически и ссылки не были статичными, было принято решение использовать **Selenium**. Это позволило имитировать действия реального пользователя в браузере (открытие страницы, ожидание загрузки элементов, клик по кнопке). Для этого потребовалась установка `chromedriver` и запуск браузера в "безголовом" режиме (`--headless`).
* Также были добавлены механизмы для обработки возможных всплывающих окон (например, баннеров с согласием на использование файлов cookie) и использования JavaScript для клика по кнопке, если стандартный клик Selenium перехватывался (`ElementClickInterceptedException`).

**Результат:** Код для этого шага находится в Canvas под названием "Скрипт для парсинга и скачивания учебных планов".

## 2. Реализация диалоговой системы (Telegram-бота)

**Инструменты:**
Библиотека `python-telegram-bot` для создания и управления ботом в Telegram.

**Проблемы и решения:**
* Необходимость безопасного хранения конфиденциальных данных (токена бота и API-ключа Gemini).
* **Решение:** Использование файлов `.env` и библиотеки `python-dotenv` для загрузки переменных окружения, что позволяет не встраивать токены напрямую в код.

**Результат:** Базовая структура бота с командами `/start` и `/help`, а также обработчиком текстовых сообщений, который изначально просто отвечал эхом. Код находится в Canvas "Базовый Telegram-бот".

## 3. Извлечение текста из PDF-файлов

**Инструменты:**
Библиотека `PyPDF2` для чтения PDF-файлов и извлечения из них текстового содержимого.

**Процесс:**
Функции для извлечения текста были интегрированы непосредственно в файл `telegram_bot.py` (в Canvas "Базовый Telegram-бот"), чтобы бот мог загружать и обрабатывать учебные планы при своем запуске.

**Результат:** Текстовое содержимое всех скачанных PDF-файлов становится доступным для использования в контексте LLM.

## 4. Интеграция с LLM (Gemini API) для ответов на вопросы

**Инструменты:**
Библиотека `requests` для выполнения HTTP-запросов к Gemini API.

**Процесс:**
* В обработчике текстовых сообщений бота формируется промпт для Gemini API. Этот промпт включает вопрос пользователя и весь извлеченный текст учебных планов в качестве контекста.
* Промпт явно инструктирует LLM отвечать только на основе предоставленного текста и сообщать, если информация отсутствует.
* Используется модель `gemini-2.0-flash`.

**Проблемы и решения:**
* **Географические ограничения Gemini API:** Возникла ошибка `"User location is not supported for the API use."`.
* **Решение:** Было рекомендовано использовать VPN для обхода региональных ограничений.
* **Ограничение длины сообщения Telegram:** Ответы от Gemini API могли превышать максимальную длину сообщения в Telegram (4096 символов).
* **Решение:** Была реализована вспомогательная функция `send_long_message`, которая автоматически разбивает длинные ответы на несколько частей и отправляет их по очереди, сохраняя читабельность (разбиение по абзацам).

**Результат:** Бот теперь способен принимать вопросы от пользователя, отправлять их в Gemini API вместе с контекстом учебных планов и возвращать сгенерированные ответы, разделяя их при необходимости.

## Дальнейшие шаги и текущее состояние проекта

Проект заложил прочный фундамент для дальнейшего развития:

* **Пункт 3 (Рекомендации по дисциплинам):** Текущая реализация позволяет LLM отвечать на вопросы, основываясь на тексте дисциплин. Для полноценных рекомендаций потребуется дополнительная логика для сбора структурированной информации о бэкграунде абитуриента (возможно, через управляемый диалог) и более сложного промпт-инжиниринга.
* **Пункт 4 (Релевантные вопросы):** Уже частично реализован через инструкции в промпте для LLM ("отвечай только на основе предоставленного текста"). Для более строгой фильтрации можно добавить предварительную классификацию вопросов перед отправкой в LLM.

## Заключение

Таким образом, задача решалась итеративно, с адаптацией к возникающим проблемам (например, сложности с парсингом, региональные ограничения API, лимиты сообщений) и последовательным добавлением функциональности.
